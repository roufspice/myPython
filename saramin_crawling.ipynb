{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "\n",
    "search_n = input(\"원하는 분야를 입력해주세요!>\")\n",
    "#saveFileNm = input(\"저장할 파일 이름을 정해주세요>\")\n",
    "\n",
    "#search_n = \"데이터분석\"\n",
    "url =\"http://www.saramin.co.kr/zf_user/search/recruit?searchType=search&searchword=\"+search_n+\"&loc_mcd=101000&company_cd=0,1,2,3,4,5,6,7,9&panel_type=&search_optional_item=y&search_done=y&panel_count=y&recruitPage=2&recruitSort=relation&recruitPageCount=50&inner_com_type=&quick_apply=\"\n",
    "urlsrc = requests.get(url)\n",
    "soup = bs(urlsrc.text, \"html.parser\")\n",
    "\n",
    "#불러올 데이터 총 개수 찾기!\n",
    "cnt_result = soup.find(\"span\", class_=\"cnt_result\").text\n",
    "cnt_result = re.sub(r\"총 |건\",\"\",cnt_result)\n",
    "cnt_result = cnt_result.split(\",\")\n",
    "totCnt = \"\"\n",
    "for i in range(len(cnt_result)):\n",
    "    totCnt += cnt_result[i]\n",
    "totCnt = int(totCnt)\n",
    "#불러올 데이터 수!\n",
    "totCnt\n",
    "\n",
    "#불러올 페이지수\n",
    "totPage = totCnt//50 +1\n",
    "totPage\n",
    "\n",
    "\n",
    "#DF선언\n",
    "saramIn_df = pd.DataFrame()\n",
    "saramIn_df_temp = pd.DataFrame()\n",
    "saramIn_df_temp = saramIn_df_temp.append(\n",
    "                {\"coID\":\"\",\n",
    "                 \"coNm\":\"\",\n",
    "                 \"r_date\":\"\",\n",
    "                 \"loc_city\":\"\",\n",
    "                 \"loc_detail\":\"\",\n",
    "                 \"cod_a\":\"\",\n",
    "                 \"cod_b\":\"\",\n",
    "                 \"cod_c\":\"\",\n",
    "                 \"content\":\"\",\n",
    "                 \"link\":\"\",\n",
    "                 \"coIndx\":\"\",\n",
    "                 #\"coIndx\":\"\",\n",
    "                }, ignore_index=True\n",
    ")\n",
    "for page in range(1,totPage+1):\n",
    "    URL = \"http://www.saramin.co.kr/zf_user/search/recruit?searchType=search&searchword=\"+search_n+\"&loc_mcd=101000&company_cd=0,1,2,3,4,5,6,7,9&panel_type=&search_optional_item=y&search_done=y&panel_count=y&recruitPage=\"+str(page)+\"&recruitSort=relation&recruitPageCount=50&inner_com_type=&quick_apply=\"\n",
    "    print(URL)\n",
    "    urlsrc = requests.get(URL)\n",
    "    \n",
    "    soup = bs(urlsrc.text, \"html.parser\")\n",
    "    comp_list = soup.find_all(\"div\",class_=\"item_recruit\")\n",
    "    \n",
    "    for i in range(len(comp_list)):\n",
    "        content = comp_list[i].find(\"h2\").find(\"a\").get(\"title\")\n",
    "        content = re.sub(r\" \",\"\",content)\n",
    "        link = comp_list[i].find(\"h2\").find(\"a\").get(\"href\")\n",
    "        link = \"http://www.saramin.co.kr/\" + link\n",
    "        r_date = comp_list[i].find(\"span\", class_=\"date\").text\n",
    "        r_date = re.sub(r\"~ \",\"\",r_date)\n",
    "        loc_city = comp_list[i].find(\"div\", class_=\"job_condition\").find_all(\"span\")[0].find_all(\"a\")[0].text\n",
    "        #loc_detail = comp_list[i].find(\"div\", class_=\"job_condition\").find_all(\"span\")[0].find_all(\"a\")[1].text\n",
    "        loc_detail=\"\"\n",
    "        if len(comp_list[i].find(\"div\", class_=\"job_condition\").find_all(\"span\")) >= 4:\n",
    "            \n",
    "            cod_a =  comp_list[i].find(\"div\", class_=\"job_condition\").find_all(\"span\")[1].text\n",
    "            cod_b = comp_list[i].find(\"div\", class_=\"job_condition\").find_all(\"span\")[2].text\n",
    "            if cod_b != \"학력무관\":\n",
    "                cod_b = re.sub(r\"↑\",\"\",cod_b)\n",
    "            cod_c = comp_list[i].find(\"div\", class_=\"job_condition\").find_all(\"span\")[3].text\n",
    "            cod_c = re.sub(r\"·\",\"\",cod_c)\n",
    "        elif len(comp_list[i].find(\"div\", class_=\"job_condition\").find_all(\"span\")) < 4:\n",
    "            cod_a =  comp_list[i].find(\"div\", class_=\"job_condition\").find_all(\"span\")[1].text\n",
    "            cod_b = comp_list[i].find(\"div\", class_=\"job_condition\").find_all(\"span\")[2].text\n",
    "            if cod_b != \"학력무관\":\n",
    "                cod_b = re.sub(r\"↑\",\"\",cod_b)\n",
    "            cod_c = \"\"\n",
    "        coID = comp_list[i].find(\"div\", class_=\"area_corp\").find(\"div\", class_=\"area_btn\").get(\"value\")\n",
    "        companyNm = comp_list[i].find(\"div\", class_=\"area_corp\").strong.a.get(\"title\")\n",
    "        coIndx = comp_list[i].find(\"h2\",class_=\"job_tit\").find_all(\"a\")[0].get(\"href\")\n",
    "        coIndx = re.findall(r\"[0-9]{8}\",coIndx)[0]\n",
    "        \n",
    "        saramIn_df_temp.iat[0,saramIn_df_temp.columns.get_loc(\"coID\")] = coID\n",
    "        saramIn_df_temp.iat[0,saramIn_df_temp.columns.get_loc(\"coNm\")] = companyNm \n",
    "        saramIn_df_temp.iat[0,saramIn_df_temp.columns.get_loc(\"r_date\")] = r_date\n",
    "        saramIn_df_temp.iat[0,saramIn_df_temp.columns.get_loc(\"loc_city\")] = loc_city\n",
    "        saramIn_df_temp.iat[0,saramIn_df_temp.columns.get_loc(\"loc_detail\")] = loc_detail\n",
    "        saramIn_df_temp.iat[0,saramIn_df_temp.columns.get_loc(\"cod_a\")] = cod_a\n",
    "        saramIn_df_temp.iat[0,saramIn_df_temp.columns.get_loc(\"cod_b\")] = cod_b\n",
    "        saramIn_df_temp.iat[0,saramIn_df_temp.columns.get_loc(\"cod_c\")] = cod_c\n",
    "        saramIn_df_temp.iat[0,saramIn_df_temp.columns.get_loc(\"content\")] = content\n",
    "        saramIn_df_temp.iat[0,saramIn_df_temp.columns.get_loc(\"link\")] = link\n",
    "        saramIn_df_temp.iat[0,saramIn_df_temp.columns.get_loc(\"coIndx\")] = coIndx\n",
    "        \n",
    "        saramIn_df = saramIn_df.append(saramIn_df_temp, ignore_index= True)\n",
    "        saramIn_df_temp.drop(0)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "saramIn_df.to_excel(\"C:\\\\Users\\\\roufs\\\\Desktop\\\\recruit\\\\saramIn07081.xlsx\")\n",
    "\n",
    "saramIn_df\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saramIn_df.rename({\"cod_a\":\"경력조건\"},axis = 1,inplace=True)\n",
    "saramIn_df.rename({\"cod_b\":\"학력조건\",\"content\":\"제목\",\"coNm\":\"회사명\",\"loc_city\":\"지역\",\"r_date\":\"모집기간\"},axis=1,inplace=True)\n",
    "saramIn_df[saramIn_df['학력조건'] == '대졸']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coIndx=comp_list[0].find(\"h2\",class_=\"job_tit\").find_all(\"a\")[0].get(\"href\")\n",
    "coIndx = re.findall(r\"[0-9]{8}\",coIndx)[0]\n",
    "coIndx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "from selenium import webdriver\n",
    "\n",
    "saramIn_nu_df = pd.DataFrame()\n",
    "saramIn_nu_df_temp = pd.DataFrame()\n",
    "saramIn_nu_df_temp = saramIn_nu_df_temp.append(\n",
    "                {\"coIndx\":\"\",\n",
    "                 \"scrap_cnt\":\"\",\n",
    "                 \"view_cnt\":\"\",\n",
    "                 #\"r_date\":\"\",\n",
    "                 #\"s_date\":\"\",\n",
    "                 \"apply_cnt\":\"\",\n",
    "                 \"apply_male\":\"\",\n",
    "                 \"apply_female\":\"\",\n",
    "                 \"apply_20s\":\"\",\n",
    "                 \"apply_30s\":\"\",\n",
    "                 \"apply_40s\":\"\",\n",
    "                 #\"coIndx\":\"\",\n",
    "                }, ignore_index=True\n",
    ")\n",
    "\n",
    "driver = webdriver.Chrome(\"C:/Users/roufs/Desktop/myPython/chromedriver.exe\")\n",
    "\n",
    "for i in saramIn_df[\"coIndx\"]:\n",
    "    url = \"http://www.saramin.co.kr/zf_user/jobs/relay/view?isMypage=no&rec_idx=\"+\"38356726\"+\"&recommend_ids=eJxdkMsRQyEMA6vJ3diWP%2BcUQv9dhISHzeS4swJpLKHMEjRh4%2BVvCSXxwETqxgGBLsQPl1PlCjfOHRcQkup14%2BOZk1inpW2fgby%2BK5zVzprdng7h6Wp%2FeOLMrj22sTwFxeUPVl2CqH3h8QQFqr%2Fx8cPFR5Zf09eFphHvuba8XKhu1kjOzoU8jPIK%2BxD%2FHkI%2FuiBfJA%3D%3D&view_type=search&searchword=데이터분석searchType=default_mysearch&gz=1&t_ref_content=generic&\"\n",
    "    driver.get(url)\n",
    "    if driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[1]/div/button[2]/span\"\"\") != None:\n",
    "        scrap_cnt = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[1]/div/button[2]/span\"\"\")[0].text\n",
    "    else:\n",
    "        pass\n",
    "    view_cnt_samp = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[2]/ul/li[1]/strong\"\"\")[0].text\n",
    "    view_cnt_samp = view_cnt_samp.split(\",\")\n",
    "    view_cnt =\"\"\n",
    "    for i in range(len(view_cnt_samp)):\n",
    "        view_cnt += view_cnt_samp[i]\n",
    "    #if driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[4]/div[2]/div/dl/dd[2]\"\"\") !=None:\n",
    "        #r_date= driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[4]/div[2]/div/dl/dd[2]\"\"\")[0].text\n",
    "        #//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[6]/div[2]/div/dl/dd[2]\n",
    "    #else:\n",
    "        #pass\n",
    "    #s_date= driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[4]/div[2]/div/dl/dd[1]\"\"\")[0].text\n",
    "    apply_cnt = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[1]/dl/dd/span\"\"\")[0].text\n",
    "    apply_male = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[2]/div/div/dl[1]/dd[2]\"\"\")[0].text\n",
    "    apply_male = re.sub(r\" 명\",\"\",apply_male)\n",
    "    apply_female = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[2]/div/div/dl[2]/dd[2]\"\"\")[0].text\n",
    "    apply_female = re.sub(r\" 명\",\"\",apply_female)\n",
    "    apply_20s = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[3]/div/div[1]/div/div/span\"\"\")[0].text\n",
    "    apply_30s = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[3]/div/div[2]/div/div/span\"\"\")[0].text\n",
    "    apply_40s = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[3]/div/div[3]/div/div/span\"\"\")[0].text\n",
    "    \n",
    "    saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"coIndx\")] = i\n",
    "    saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"scrap_cnt\")] = scrap_cnt\n",
    "    saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"view_cnt\")] = view_cnt\n",
    "    #saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"r_date\")] = r_date\n",
    "    #saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"s_date\")] = s_date\n",
    "    saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_cnt\")] = apply_cnt\n",
    "    saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_male\")] = apply_male\n",
    "    saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_female\")] = apply_female\n",
    "    saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_20s\")] = apply_20s\n",
    "    saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_30s\")] = apply_30s\n",
    "    saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_40s\")] = apply_40s\n",
    "    \n",
    "    saramIn_nu_df = saramIn_nu_df.append(saramIn_nu_df_temp,ignore_index=True)\n",
    "    print(str(i),\"완료\")\n",
    "    saramIn_nu_df_temp.drop(0)\n",
    "    \n",
    "saramIn_nu_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "from selenium import webdriver\n",
    "\n",
    "saramIn_nu_df = pd.DataFrame()\n",
    "saramIn_nu_df_temp = pd.DataFrame()\n",
    "saramIn_nu_df_temp = saramIn_nu_df_temp.append(\n",
    "                {\"coIndx\":\"\",\n",
    "                 \"scrap_cnt\":\"\",\n",
    "                 \"view_cnt\":\"\",\n",
    "                 \"r_date\":\"\",\n",
    "                 \"s_date\":\"\",\n",
    "                 \"apply_cnt\":\"\",\n",
    "                 \"apply_male\":\"\",\n",
    "                 \"apply_female\":\"\",\n",
    "                 \"apply_20s\":\"\",\n",
    "                 \"apply_30s\":\"\",\n",
    "                 \"apply_40s\":\"\",\n",
    "                 #\"coIndx\":\"\",\n",
    "                }, ignore_index=True\n",
    ")\n",
    "\n",
    "driver = webdriver.Chrome(\"C:/Users/roufs/Desktop/myPython/chromedriver.exe\")\n",
    "\n",
    "url = \"http://www.saramin.co.kr/zf_user/jobs/relay/view?isMypage=no&rec_idx=\"+\"38356726\"+\"&recommend_ids=eJxdkMsRQyEMA6vJ3diWP%2BcUQv9dhISHzeS4swJpLKHMEjRh4%2BVvCSXxwETqxgGBLsQPl1PlCjfOHRcQkup14%2BOZk1inpW2fgby%2BK5zVzprdng7h6Wp%2FeOLMrj22sTwFxeUPVl2CqH3h8QQFqr%2Fx8cPFR5Zf09eFphHvuba8XKhu1kjOzoU8jPIK%2BxD%2FHkI%2FuiBfJA%3D%3D&view_type=search&searchword=데이터분석searchType=default_mysearch&gz=1&t_ref_content=generic&\"\n",
    "driver.get(url)\n",
    "if driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[1]/div/button[2]/span\"\"\") != None:\n",
    "    scrap_cnt = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[1]/div/button[2]/span\"\"\")[0].text\n",
    "else:\n",
    "    pass\n",
    "view_cnt_samp = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[2]/ul/li[1]/strong\"\"\")[0].text\n",
    "view_cnt_samp = view_cnt_samp.split(\",\")\n",
    "view_cnt =\"\"\n",
    "for i in range(len(view_cnt_samp)):\n",
    "    view_cnt += view_cnt_samp[i]\n",
    "\n",
    "r_date= driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[4]/div[2]/div/dl/dd[2]\"\"\")[0].text\n",
    "s_date= driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[4]/div[2]/div/dl/dd[1]\"\"\")[0].text\n",
    "apply_cnt = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[1]/dl/dd/span\"\"\")[0].text\n",
    "apply_male = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[2]/div/div/dl[1]/dd[2]\"\"\")[0].text\n",
    "apply_male = re.sub(r\" 명\",\"\",apply_male)\n",
    "apply_female = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[2]/div/div/dl[2]/dd[2]\"\"\")[0].text\n",
    "apply_female = re.sub(r\" 명\",\"\",apply_female)\n",
    "apply_20s = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[3]/div/div[1]/div/div/span\"\"\")[0].text\n",
    "apply_30s = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[3]/div/div[2]/div/div/span\"\"\")[0].text\n",
    "apply_40s = driver.find_elements_by_xpath(\"\"\"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[5]/div[2]/div/div/div[3]/div/div[3]/div/div/span\"\"\")[0].text\n",
    "    \n",
    "saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"coIndx\")] = i\n",
    "saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"scrap_cnt\")] = scrap_cnt\n",
    "saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"view_cnt\")] = view_cnt\n",
    "saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"r_date\")] = r_date\n",
    "saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"s_date\")] = s_date\n",
    "saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_cnt\")] = apply_cnt\n",
    "saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_male\")] = apply_male\n",
    "saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_female\")] = apply_female\n",
    "saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_20s\")] = apply_20s\n",
    "saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_30s\")] = apply_30s\n",
    "saramIn_nu_df_temp.iat[0,saramIn_nu_df_temp.columns.get_loc(\"apply_40s\")] = apply_40s\n",
    "\n",
    "saramIn_nu_df_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s_df= saramIn_df.set_index(\"coID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(len(s_df.index.unique()))\n",
    "print(s_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"키워드 값만 찾아오기!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_01 = input(\"첫번째 키워드를 입력하세요\")\n",
    "keyword_02 = input(\"두번째 키워드를 입력하세요\")\n",
    "keyword_03 = input(\"세번째 키워드를 입력하세요\")\n",
    "\n",
    "len(saramIn_df['제목'])\n",
    "data_analyist_list =[]\n",
    "for i in range(len(saramIn_df['제목'])):\n",
    "    if keyword_01 in saramIn_df['제목'][i] or \"keyword_02\" in saramIn_df['제목'][i] or keyword_03 in saramIn_df['제목'][i]:\n",
    "        data_analyist_list.append(i)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "saramIn_key_df =saramIn_df.loc[data_analyist_list,:]\n",
    "\n",
    "saramIn_key_df.to_excel(\"C:\\\\Users\\\\roufs\\\\Desktop\\\\recruit\\\\saramIn_keyword.xlsx\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_d = []\n",
    "\n",
    "for i in range(len(saramIn_df['제목'])):\n",
    "    if \"개발자\" in saramIn_df['제목'][i]:\n",
    "        continue\n",
    "    else:\n",
    "        not_d.append(i)\n",
    "\n",
    "saramIn_df.loc[not_d,:]\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
